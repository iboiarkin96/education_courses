{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "<center><span style=\"color:black; font-weight: bold; font-size:24pt\">Основы статистики. Часть 2</span></center>\n",
    "<br/><br/>\n",
    "<center><span style=\"color:gray; font-weight: bold; font-size:18pt\">Анализ номинативных данных</span></center>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Критерий χ²-Пирсона</span></center>\n",
    "\n",
    "**H<span style = \"font-size: 7pt\">0</span>:** Распределение частот не отличимо от ожидаемого<br/>\n",
    "**H<span style = \"font-size: 7pt\">1</span>:** Распределение частот отличимо от ожидаемого<br/>\n",
    "**Задача:** Определить, насколько статичстически значимы различия между ожидаемыми и эмпирическими значениями\n",
    "\n",
    "<br/>\n",
    "<span style=\"color: orange; font-weight: bold; font-size:12pt\">Расстояние Хи-квадрат:</span>\n",
    "<br/><br/>\n",
    "<center><strong><i>χ² = ∑( (O<span style = \"font-weight: bold; font-size: 7pt\">i</span> - E<span style = \"font-weight: bold; font-size: 7pt\">i</span>)² / E<span style = \"font-weight: bold; font-size: 7pt\">i</span> )</i></strong></center>\n",
    "\n",
    "где значения <i>O<span style = \"font-weight: bold; font-size: 7pt\">i</span> (Observed)</i> - наблюдаемые частоты, <i>E<span style = \"font-weight: bold; font-size: 7pt\">i</span> (Expexted)</i> - ожидаемые частоты.\n",
    "\n",
    "<br/>\n",
    "\n",
    "![x2_rasstoyznie](pictures/x2_rasstoyznie.jpg)\n",
    "\n",
    "<br/>\n",
    "<span style=\"color: orange; font-weight: bold; font-size:12pt\">Распределение <i>χ²</i> с <i>k</i> степенями свободы</span> (<i>k</i> - сумма слагаемых) — распределение суммы квадратов <i>k</i> независимых стандратных (со средним M<span style= \"font-weight: bold; font-size:7pt\">z</span> = 0 и дисперсией D<span style= \"font-weight: bold; font-size:7pt\">z</span> = 1) случайных величин, распределённых нормальным образом.\n",
    "\n",
    "На графике видно, что отклонение от заданной точки до нуля (<i>χ²</i>) равняется гипотенузе прямоугольного треугольника со сторонами, равными значениям координат по осям <i>OX</i> и <i>OY</i>:\n",
    "\n",
    "![dvum_raspr](pictures/dvum_raspr.jpg)\n",
    "\n",
    "![x2_rasspr](pictures/x2_rasspr.jpg)\n",
    "\n",
    "Чем больше число степеней свободы у распределения хи-квадрат, тем более симметричным становится такое распределение, и тем больше распределение Хи-квадрат стремится к нормальному.\n",
    "\n",
    "[Почему df = N-1 ?](https://stepik.org/lesson/24814/step/10?unit=7105) <br/>\n",
    "<span style=\"color: gray\">При заданном количестве значений только <i>N-1</i> значений будут независимы, зная их все, последнюю <i>1</i> мы всегда можем предсказать, следовательно <i>1</i> значение всегда не независимо от других и его не следует учитывать.</span>\n",
    "\n",
    "<span style=\"color: green; font-weight: bold; font-size:12pt\">Расчёт p-value</span> - [Online-калькулятор для вычисления p-value](https://gallery.shinyapps.io/dist_calc/)\n",
    "\n",
    "<br/>\n",
    "<ins>Рассчитаем значение <i>χ²</i> и p-value в Python:</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хи-квадрат = 2.62, p = 0.270\n"
     ]
    }
   ],
   "source": [
    "#from scipy import stats\n",
    "\n",
    "chi2_value, chi2_pvalue = stats.chisquare([18, 55, 27], f_exp=[25, 50, 25]) \n",
    "# Первый массив - эмпирические значения\n",
    "# Второй массив(f_exp=) - ожидаемые значения, можно не указывать, если ожидаемые значения равномерны\n",
    "\n",
    "print(f'Хи-квадрат = {chi2_value:.2f}, p = {chi2_pvalue:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<ins>Какой процент наблюдений лежит в диапазоне:</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В диапазоне от 2 до 4 у распределения хи-квадрат с двумя степенями свободы лежит 23.3% наблюдений.\n"
     ]
    }
   ],
   "source": [
    "#from scipy import stats\n",
    "chi2_down=stats.chi2.cdf(2 , 2) # - (нижняя граница диапазона, число степеней свободы)\n",
    "chi2_up=stats.chi2.cdf(4 , 2) # - (верхняя граница диапазона, число степеней свободы)\n",
    "# stats.chi2.cdf() - вероятность попасть в 95%, т.е. значение, обратное p-value (= 1 - p-value)\n",
    "\n",
    "chi2_interval = chi2_up - chi2_down\n",
    "print(f'В диапазоне от 2 до 4 у распределения хи-квадрат с двумя степенями свободы лежит {chi2_interval:.1%} наблюдений.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Анализ таблиц сопряженности</span></center>\n",
    "\n",
    "**H<span style = \"font-size: 7pt\">0</span>:** Распределение частот не отличимо от ожидаемого<br/>\n",
    "**H<span style = \"font-size: 7pt\">1</span>:** Распределение частот отличимо от ожидаемого, иными словами: номинативные переменные взаимосвязаны между собой<br/>\n",
    "**Задача:** Исследование наличия взаимосвязи между двумя номинативными переменными\n",
    "\n",
    "<br/>\n",
    "\n",
    "<span style=\"color: green; font-weight: bold; font-size:12pt\">Расчёт ожидаемых значений:</span>\n",
    "\n",
    "<br/>\n",
    "<center><strong><i>f<span style = \"font-weight: bold; font-size: 7pt\">ij</span> = (f<span style = \"font-weight: bold; font-size: 7pt\">i</span> * f<span style = \"font-weight: bold; font-size: 7pt\">j</span>)/ N</i></strong></center>\n",
    "\n",
    "где <i>f<span style = \"font-weight: bold; font-size: 7pt\">i</span></i> - сумма в строке, <i>f<span style = \"font-weight: bold; font-size: 7pt\">j</span></i> - сумма в столбце, <i>N</i> - количество наблюдений в выборке.\n",
    "\n",
    "<br/>\n",
    "\n",
    "![ozhid_znacheniya](pictures/ozhid_znacheniya.jpg)\n",
    "\n",
    "Для поиска взаимосвязи между номинативными переменными, применяем критерий <i>χ²</i>-Пирсона, который проверяет гипотезу о том, что наблюдаемое распределение номинативной переменной отличается от ожидаемого. И рассчитываем p-value со степенями свобод, равными:\n",
    "\n",
    "<br/>\n",
    "<center><strong><i>df = (n - 1) * (m - 1)</i></strong></center>\n",
    "\n",
    "где <i>n</i> - количество столбцов таблицы, <i>m</i> - количество строк\n",
    "\n",
    "<br/>\n",
    "В теории распределение <i>χ²</i> непрерывно, тогда как вычисляемые значения всегда дискретны, в результате <i>H<span style = \"font-size: 7pt\">0</span></i> может отвергаться слишком часто. Чтобы скорректировать значение p-уровня значимости применяется <span style=\"color: orange; font-weight: bold; font-size:12pt\">Поправка Йетса</span> на непрерывность. (Используется для анализа таблицы сопряженности два на два, где значения ожидаемых и наблюдаемых частот в каждой ячейке больше 5, но меньше 10).<br/>\n",
    "\n",
    "<br/>\n",
    "<center><strong><i>χ²<span style = \"font-weight: bold; font-size: 7pt\">Yates</span> = ∑( (|f<span style = \"font-weight: bold; font-size: 5pt\">O</span> - f<span style = \"font-weight: bold; font-size: 5pt\">E</span>| - 0.5)² ) / f<span style = \"font-weight: bold; font-size: 5pt\">E</span></i></strong></center>\n",
    "\n",
    "где f<span style = \"font-weight: bold; font-size: 5pt\">O</span> - эмпирическое значение в ячейке, f<span style = \"font-weight: bold; font-size: 5pt\">E</span> - ожидаемое значение в ячейке\n",
    "\n",
    "<br/>\n",
    "<ins>Рассчитаем ожидаемые значения, число степеней свобод, значение <i>χ²</i> и p-value в Python:</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хи-квадрат = 7.114 \n",
      "p-value = 0.008 \n",
      "df = 1\n",
      "\n",
      "Ожидаемые значения:\n",
      "[[13.63636364 11.36363636]\n",
      " [10.36363636  8.63636364]]\n"
     ]
    }
   ],
   "source": [
    "#from scipy import stats\n",
    "observed_array = [ [18, 7], [6, 13] ]\n",
    "\n",
    "chi2_value, p_value, df_value, expected_array = stats.chi2_contingency(observed_array, correction=False) \n",
    "# 'correction=True' - поправка Йетса, работает по умолчанию при df=1, поэтому можно удалить из формулы и ничего не изменится\n",
    "\n",
    "print(f'Хи-квадрат = {chi2_value:.3f} \\np-value = {p_value:.3f} \\ndf = {df_value}')\n",
    "print(f'\\nОжидаемые значения:\\n{expected_array}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<span style=\"color: green; font-weight: bold; font-size:12pt\">Интерпретретация остатков:</span>\n",
    "\n",
    "Анализ остатков (разница между ожидаемыми и эмпирическими значениями) позволяет выявить, какие именно частоты значимо отклоняются от ожидаемых значений.\n",
    "\n",
    "+ Если значения стандартизированных остатков больше 3х, можно считать, что в этой ячейке зафиксированы значимые отклонения.\n",
    "\n",
    "<br/>\n",
    "<ins>Построим наглядный график в Python:</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "pill_data = {('Normal', 'Aspirine'): 18, \n",
    "             ('Normal', 'Placebo'): 7,\n",
    "             ('Trombosis', 'Aspirine'): 6,\n",
    "             ('Trombosis', 'Placebo'): 13\n",
    "            }\n",
    "# Значения 18, 7, 6, 13 являются входными значениями и соответсвуют таблице observed_array = [ [18, 7], [6, 13] ]\n",
    "\n",
    "my_plot = mosaic(pill_data, gap=.009)\n",
    "\n",
    "# Ширина прямоугольников соответствует количеству наблюдений\n",
    "# Высота прямоугольников соответствует отклонению ожидаемых и наблюдаемых частот в этой ячейке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<span style=\"color: green; font-weight: bold; font-size:12pt\">Условия применимости критерий χ² при анализе таблиц сопряжённости:</span>\n",
    "\n",
    "+ Все наблюдения независимы\n",
    "+ Минимальное количество наблюдений в каждой из ячеек должно быть больше 5 (иначе нарушается предположение о нормальном распределении переменных)\n",
    "\n",
    "В случае когда размер выборки очень маленький и наблюдений в каждой из ячеек недостаточно (меньше 5), используется <span style=\"color: violet; font-weight: bold; font-size:13pt\">точный критерий Фишера</span>:\n",
    "\n",
    "![tochniy_fisher](pictures/tochniy_fisher.jpg) \n",
    "[Как выводится эта формула](https://stepik.org/lesson/26447/step/3?unit=8328)\n",
    "\n",
    "![tochniy_fisher_primer](pictures/tochniy_fisher_primer.jpg)\n",
    "\n",
    "Почему не рассматриваются варианты 3,1 + 4,0? -> В тесте Фишера фиксированы и суммы по строкам, и суммы по столбцам.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<ins>Расчёт p-value с применением точного критерия Фишера в Python:</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48571428571428527\n"
     ]
    }
   ],
   "source": [
    "#from scipy import stats\n",
    "odds_ratio, p_value = stats.fisher_exact([[1, 3], [3, 1]])  # odds_ratio - отношение шансов\n",
    "\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<center><span style=\"color:gray; font-weight: bold; font-size:18pt\">Метод логистической регрессии</span></center>\n",
    "<br/>\n",
    "<span style=\"color: violet; font-weight: bold; font-size:14pt\">Логистическая регрессия</span> используется для исследования взаимосвязи между номинативной зависимой переменной, имеющей всего 2 градации, и различными независимыми переменными (в качестве предикторов могут быть как номинативные, так и количественные переменные).\n",
    "\n",
    "Номинативную переменную с двумя градациями можно представить как два зависимых друг от друга вероятностных исхода, равных <i>p</i> и <i>(1 - p)</i>. <br/>\n",
    "Тогда регрессионная модель, в которой зависимая переменная — это номинативная переменная с двумя градациями:\n",
    "\n",
    "![log_regr](pictures/log_regr.jpg)\n",
    "\n",
    "<span style=\"color: orange; font-weight: bold; font-size:12pt\">Odds (шансы)</span> **= <i>p / (1 - p)</i>** - это отношение вероятности успеха <i>(p)</i> к вероятности неудачи <i>(1 - p)</i> , ∈ \\[0; +∞)\n",
    "\n",
    "<span style=\"color: orange; font-weight: bold; font-size:12pt\">Логарифм шанса <i>(log odds)</i></span> = <i>logit (p)</i> , ∈ (-∞; +∞)\n",
    "\n",
    "+ если <i>log odds > 0 </i>, то <i>p > 1 - p </i>\n",
    "+ если <i>log odds < 0 </i>, то <i>p < 1 - p </i>\n",
    "\n",
    "![log_shans](pictures/log_shans.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2689414213699951"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import math\n",
    "\n",
    "# Предположим, мы подбросили монетку 100 раз, и 70 раз выпал орел. Чему равняется натуральный логарифм шансов выпадения решки?\n",
    "math.log(30/70)\n",
    "\n",
    "# Предположим, что мы получили логарифм шансов выпадения решки, равный -1. Тогда вероятность выпадения решки равняется:\n",
    "math.exp(-1) / (1 + math.exp(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Модель без предикторов</span></center>\n",
    "\n",
    "<br/>Модель без предикторов описывается уравнением: **<i>y = intercept</i>** (одному числу, без предикторов)\n",
    "\n",
    "<span style=\"color: orange; font-weight: bold; font-size:12pt\">Intercept</span> - натуральный логарифм шансов положительного исхода. И свободный член логистической регресии.\n",
    "\n",
    "Т.е. мы хотим предсказать логарифм шансов, используя только одно число: **<i>log( p/(1-p) ) = intercept</i>**\n",
    "\n",
    "<br/>\n",
    "\n",
    "**H<span style = \"font-size: 7pt\">0</span>:** Нет никакой разницы между исходом №1 и исходом №2 и нормальное распределение описывает распределение коэффициентов логистической регрессии:\n",
    "+ <i>p = 1 - p</i>;\n",
    "+ <i>odds = 1</i>;\n",
    "+ Логарифм шансов <i>logit(p) = 0</i> , т.е. logit(p) (он же intercept) имеет нормальное распределение со средним равным 0\n",
    "\n",
    "<br/>\n",
    "\n",
    "![intercept_only_model](pictures/intercept_only_model.jpg)\n",
    "\n",
    "Интерпретация расчётной таблицы:\n",
    "+ Estimate - значение intercept (логарифма шансов)\n",
    "+ Полученная в расчётах стандартная ошибка (<i>se</i>) - это стандартное отклонение, которое имело бы нормальное распределение коэфициента intercept со средним равным 0\n",
    "+ Тогда если разделить значение коэфициента intercept на стандартную ошибку, то получим <i>z-value</i> – расстояние до 0 в стандартных отклонениях.\n",
    "+ Pr(>|z|) - значение <i>p-value</i>, т.е. вероятность получить такое или ещё более сильное отличие intercept от 0 при условии, что верна нулевая гипотеза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "С помощью логистической регрессии без предикторов мы захотели узнать, правда ли, \n",
    "что сдавая Анатолию Дмитриевичу, легче провалить экзамен, чем сдать. \n",
    "В нашей выборке было 50 студентов. Часть из них сдала экзамен (положительный исход), \n",
    "а часть - нет (отрицательный исход). Свободный член нашей регрессии оказался равен -0.8472979. \n",
    "Сколько человек всё-таки сдало экзамен?\n",
    "'''\n",
    "\n",
    "def find_n_sdalo (logit_p, n_vsego):\n",
    "    p = math.exp(logit_p) / (1 + math.exp(logit_p))\n",
    "    n_sdalo = round(p * n_vsego)\n",
    "    return n_sdalo\n",
    "\n",
    "logit_p = -0.8472979\n",
    "n_vsego = 50\n",
    "\n",
    "find_n_sdalo (logit_p, n_vsego)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Модель с одним номинативным предиктором</span></center>\n",
    "\n",
    "Таблица зависимостей шансов выжить у мужчин и женщин:\n",
    "![y_n_f_m](pictures/y_n_f_m.jpg)\n",
    "\n",
    "<br/><i>odds_male</i> = 93 / 360 = 0.26\n",
    "<br/><i>odds_female</i> = 197 / 64 = 3.08\n",
    "\n",
    "**intercept** - натуральный логарифм шансов положительного исхода для женщин\n",
    "<br/><i>log(odds_female)</i> = 1.12\n",
    "\n",
    "**коэф-т при Х** - натуральный логарифм отношения шансов положительного исхода для мужчин и шансов для женщин (он же - разность логарифмов шансов)\n",
    "<br/><i>odds_ratio = odds_male / odds_female</i>\n",
    "<br/><i>log(odds_ratio) </i> = - 2.48\n",
    "<br/>По свойству логарифмов: <i>log(odds_ratio) = log(odds_male) - log(odds_female)</i> \n",
    "\n",
    "![log_model_1x](pictures/log_model_1x.jpg)\n",
    "\n",
    "Т.к. переменные Female и Male зависимы друг от друга (мультиколлинеарны), разумно в построении модели использовать только одну из них (любую, у нас выбраны женщины, просто по алфавиту), а вторую назначить значением intercept. Поэтому, смотрим, какой градации-предиктора нет среди коэффициентов, это и будет intercept\n",
    "\n",
    "![ln_odds](pictures/ln_odds.jpg)\n",
    "<br/><i>log(odds_female)</i> = 1.12 - 2.48 * Sex_Male = 1.12 - 2.48 * 0 = 1.12\n",
    "<br/><i>log(odds_male)</i> = 1.12 - 2.48 * Sex_Male = 1.12 - 2.48 * 1 = - 1.35\n",
    "\n",
    "<br/>Интерпетация таблицы, если значений зависимой переменной более двух:\n",
    "\n",
    "![log_regr_1x-3](pictures/log_regr_1x-3.png)\n",
    "\n",
    "<br/>В отличии от теста χ²-Пирсона, логистическая регрессия не только указала что две переменные взаимосвязаны, но указала шансы для разных градаций независимой переменной.\n",
    "\n",
    "<br/>[Сколько предикторов наиболее удачно включитьв логистическую модель?](https://stepik.org/lesson/26555/step/10?unit=8403)\n",
    "\n",
    "<br/><ins>Расчёт логистической модели с одним номинативным предиктором в Python:</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  714\n",
      "Model:                            GLM   Df Residuals:                      712\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -375.35\n",
      "Date:                Tue, 05 May 2020   Deviance:                       750.70\n",
      "Time:                        14:17:20   Pearson chi2:                     714.\n",
      "No. Iterations:                     4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1243      0.144      7.814      0.000       0.842       1.406\n",
      "0             -2.4778      0.185    -13.392      0.000      -2.840      -2.115\n",
      "==============================================================================\n",
      "\n",
      "\n",
      "\n",
      "                       Generalized Linear Model Regression Results                        \n",
      "==========================================================================================\n",
      "Dep. Variable:     ['Survived[0]', 'Survived[1]']   No. Observations:                  714\n",
      "Model:                                        GLM   Df Residuals:                      712\n",
      "Model Family:                            Binomial   Df Model:                            1\n",
      "Link Function:                              logit   Scale:                          1.0000\n",
      "Method:                                      IRLS   Log-Likelihood:                -375.35\n",
      "Date:                            Tue, 05 May 2020   Deviance:                       750.70\n",
      "Time:                                    14:17:20   Pearson chi2:                     714.\n",
      "No. Iterations:                                 4                                         \n",
      "Covariance Type:                        nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      -1.1243      0.144     -7.814      0.000      -1.406      -0.842\n",
      "Sex[T.male]     2.4778      0.185     13.392      0.000       2.115       2.840\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "#import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf\n",
    "\n",
    "category_columns = { col: 'category' for col in ['Survived', 'Sex'] }  # приведение выбранных колонок к категориальному\n",
    "\n",
    "data_titanic = pd.read_csv('https://stepic.org/media/attachments/course/524/train.csv', dtype=category_columns)\n",
    "data_titanic = data_titanic[data_titanic.Age.notnull()]\n",
    "\n",
    "# Зависимая переменная обычно обозначается как \"Y\" или \"y\"\n",
    "Y = data_titanic.loc[:,'Survived'].cat.codes\n",
    "\n",
    "# То о чем говорил преподаватель: колонку пол c двумя градациями нужно трансформировать в 2 колонки для каждого пола\n",
    "X = sm.add_constant( data_titanic.loc[:,'Sex'].cat.codes )\n",
    "\n",
    "#\n",
    "# ВЫЧИСЛЯЕМ  \n",
    "#\n",
    "# Классическое представление результат-предиктор(ы), которое используется в классификаторах\n",
    "glm_binom = sm.GLM(Y, X, family=sm.families.Binomial())\n",
    "res = glm_binom.fit()\n",
    "\n",
    "# Можно и так (кто привык к R)\n",
    "glm_binom_rstyle = smf.glm(formula=\"Survived ~ Sex\", data=data_titanic, family=sm.families.Binomial())\n",
    "res_rstyle = glm_binom_rstyle.fit()\n",
    "\n",
    "\n",
    "print( res.summary() )\n",
    "print('\\n\\n')\n",
    "print( res_rstyle.summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Модель с двумя номинативными предикторами</span></center>\n",
    "\n",
    "<br/>Таблицы зависимостей шансов выжить у мужчин и женщин в зависимости от класса:\n",
    "\n",
    "![y_n_f_m_1_2_3](pictures/y_n_f_m_1_2_3.png)\n",
    "\n",
    "На графике:\n",
    "\n",
    "![gr_y_n_f_m_1_2_3](pictures/gr_y_n_f_m_1_2_3.jpg)\n",
    "\n",
    "\n",
    "Интерпретация таблицы:\n",
    "\n",
    "![tab_y_n_f_m_1_2_3](pictures/tab_y_n_f_m_1_2_3.jpg)\n",
    "\n",
    "<br/>Уравнение регрессии:\n",
    "\n",
    "<br/><center><i>ln(odds) = 3.3 - 3.7\\*SexMale - 0.88\\*PclassSecond - 3.46\\*PclassThird - 0.42\\*SexMale\\*PclassSecond  + 2.15\\*SexMale\\*PclassThird</i></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Смешаная регрессионная модель</span></center>\n",
    "\n",
    "Модель, в которой учитываются и количественные и номинативные переменные\n",
    "\n",
    "![dif_regr](pictures/dif_regr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<center><span style=\"color:gray; font-weight: bold; font-size:18pt\">Непараметрические методы</span></center>\n",
    "<br/><br/>\n",
    "<center><span style=\"color: violet; font-weight: bold; font-size:14pt\">U-критерий Манна-Уитни</span></center>\n",
    "\n",
    "<span style=\"color: gray\">Непараметрический аналог <i>t</i>-критерия Стьюдента. Используется для оценки различий между двумя независимыми выборками, в которых признак измерен в метрической или ранговой шкале.</span>\n",
    "\n",
    "[Видео на Stepik](https://stepik.org/lesson/26822/step/3?unit=8557)\n",
    "\n",
    "Самым популярным непараметрическим критерием для сравнения двух групп является U-критерий Манна — Уитни. Логика данного критерия заключается в том, что вместо сравнения средних значений в двух выборках критерий сравнивает сумму рангов (не медианы, как многие думают). Мы сначала упорядочиваем все данные, затем рассчитываем сумму рангов в каждой из групп.\n",
    "\n",
    "Затем для каждой из выборок рассчитывается показатель:\n",
    "\n",
    "![U_1](pictures/U_1.jpg)\n",
    "\n",
    "Наименьшее из полученных значений и выступает в качестве статистики теста. Легко показать, что при условии верности нулевой гипотезы распределение этой статистики подчиняется нормальному распределению, где \n",
    "\n",
    "![U_2](pictures/U_2.jpg)\n",
    "\n",
    "что и позволяет нам рассчитать вероятность получить наблюдаемые или еще более выраженные различия суммы рангов.\n",
    "\n",
    "**Разумно применять вместо t - теста:**\n",
    "\n",
    "1. Распределения хотя бы в одной из выборок значительно отличается от нормального. \n",
    "2. Есть заметные выбросы в данных. \n",
    "3. В некоторых задачах мощность теста даже выше, чем t критерия (например, когда обеих выборках наблюдается заметная асимметрия в одинаковом направлении). \n",
    "\n",
    "**Неразумно применять:**\n",
    "\n",
    "1. Выборки разного размера, с различным направлением асимметрии.  \n",
    "\n",
    "<br/><br/>\n",
    "<center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Критерий Краскела-Уоллиса</span></center>\n",
    "\n",
    "Если при сравнении трёх и более групп нарушаются требования и к гомогенности дисперсий и к нормальности распределений, лучше применять непараметрический аналог дисперсионного анализа - критерий Краскела-Уоллиса.\n",
    "\n",
    "![KruskalWallis_1](pictures/KruskalWallis_1.jpg)\n",
    "\n",
    "![KruskalWallis_2](pictures/KruskalWallis_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<center><span style=\"color:gray; font-weight: bold; font-size:18pt\">Кластерный анализ и метод главных компонент</span></center><br/>\n",
    "\n",
    "Метод кластерного анализа относится к группе методов \"обучение без учителя\". Это значит, что никто не знает правильного ответа на интересующий нас вопрос и нет никакой обратной связи.\n",
    "\n",
    "**Постановка задачи:** Разбить данные на группы\n",
    "\n",
    "<span style=\"color: orange; font-weight: bold; font-size:12pt\">Кластерный анализ</span> - анализирует наблюдения (по строкам), и отвечает на вопросы, есть ли в данных подгруппы/кластеры испытуемых и сколько таких кластеров лучше выделить.\n",
    "\n",
    "<span style=\"color: orange; font-weight: bold; font-size:12pt\">Метод главных компонент</span> - анализирует наблюдения (по столбцам), и отвечает на вопрос можно ли сократить размерность данных, объединив некоторые из них в группы (интегративные переменные).\n",
    "\n",
    "<br/><br/>\n",
    "<center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Кластерный анализ методом k-средних</span></center>\n",
    "<br/>\n",
    "\n",
    "**Алгоритм метода k-средних:**\n",
    "1. Сами решаем на сколько кластеров будем делить.\n",
    "2. Случайно выбираем начальные позиции центроидов кластера.\n",
    "3. Для каждого наблюдения определяем, к какому центроиду он ближе всего.\n",
    "4. Обновим позиции центроидов (среднее по каждой переменной для группы).\n",
    "5. Если принадлежности некоторых точек изменились, то пункт 4, иначе алгоритм сошелся.\n",
    "\n",
    "<span style=\"color: orange; font-weight: bold; font-size:12pt\">Центроиды</span> - геометрические центры предполагаемых кластеров с координатами \\[ср.значение переменной OX в границах кластера; ср.значение переменной OY в границах кластера\\]\n",
    "\n",
    "[Визуализация метода](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)\n",
    "\n",
    "В методе существует элемент случайности. При многократном повторении кластеризации на одних и тех же данных мы можем получать различные варианты кластерного решения. Чем менее явно представлена в наших данных кластерзация наблюдений, тем более существенными могут оказаться различия. \n",
    "\n",
    "Возможно метод сойдется не очень удачно: метод “увяз” в локальном минимуме. \n",
    "**Решения:** \n",
    "+ Начальные точки брать наиболее далеко друг от друга; \n",
    "+ Провести кластерный анализ много раз с разными начальными позициями. (Если каждый раз из разных случайных начальных положений центроидов, кластерный анализ приходит в одно и то же положение, скорее всего, это не случайно)\n",
    "\n",
    "<br/>\n",
    "<span style=\"color: green; font-weight: bold; font-size:12pt\">Оптимальное число кластеров</span>\n",
    "\n",
    "Для того, чтобы выяснить, какое число кластеров оптимально, можно многократно проводить кластерный анализ, каждый раз выделяя разное кол-во кластеров и каждый раз забисываем значение общей внутрикластерной суммы квадратов.\n",
    "\n",
    "Если добавление одного кластера в наши данные значительно понижает общую сумму квадратов, то в увелечении числа кластеров есть смысл. Когда последующее увеличение кластеров уже не оказывает такого сильного влияния, значит мы нашли оптимальное число кластеров.\n",
    "\n",
    "Если при увелечении числа кластеров плавное снижение общей внтуригрупповой суммы квадратов, то значит нет явной класторной структуры в данных.\n",
    "\n",
    "![klaster](pictures/klaster.jpg)\n",
    "\n",
    "<ins>Расчёт внутригрупповой суммы квадратов в Python:</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 5.]]\n",
      "146.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#import numpy as np\n",
    "\n",
    "# Запишем координаты точек в виде массива numpy\n",
    "X = np.array([[-3, 3], [1, 4], [2, 6], [3, 8], [5, 2], [6, 11], [7, 1]])\n",
    "\n",
    "# Обучим модель KMeans на нашем массиве с одним кластером\n",
    "kmeans = KMeans(n_clusters=1).fit(X)\n",
    "\n",
    "# Выведем координаты центроида данного кластера\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "# Выведем сумму квадратов расстояний точек от центроида = аттрибут модели kmeans\n",
    "print(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Иерархическая кластеризация</span></center>\n",
    "\n",
    "**Идея метода:**\n",
    "+ Рассчитывается расстояние от каждой точки до каждой точки \n",
    "+ Производится кластеризация методами иереархической кластеризации, например:\n",
    " + [метод одиночной связи (ближайшего соседа)](https://stepik.org/lesson/27110/step/2?unit=8682) - Постепенно объеденяет две самые близкие точки в кластер, заменея их центроидом. В первую очередь объединяет самые близкие точки.\n",
    " + метод дальнего соседа - в последнюю очередь объединяет самые близкие точки.\n",
    " \n",
    "![klaster2](pictures/klaster2.png)\n",
    "\n",
    "![klaster1](pictures/klaster1.png)\n",
    "\n",
    "**Методы иерархической кластеризации и k-средних можно комбинировать**. Сначала применить метод иерархической кластеризации, оценить полученное количество веток, и использовать это число для метода k-средних."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Метод главных компонент</span></center> \n",
    " \n",
    "![pca](pictures/pca.png)\n",
    "\n",
    "В случае сильной корреляции двух переменных, регрессионная прямая может стать осью главной компоненты (РС1). Тогда значения новой интегративной переменной - это проекция(расстояние) на ось РС1. \n",
    "\n",
    "Значения по оси РС1 - это значения корреляции м/у двумя переменными. Например, OX-рост OY-вес, тогда РС1-конституция тела.\n",
    "\n",
    "Чем сильнее корреляция м/у переменными, тем меньше информации потеряется. При этом \"знак\" отклонения не учитывается, т.е. зная только значение по оси РС1 мы не можем знать, в какую сторону от регр. прямой отклоняется предсказ.наблюдение.\n",
    "\n",
    "Информация о \"знаке\" предсказ. значения может хранится в оси РС2 - перпендикуляру оси РС1. Но с учётом информациии по оси РС2, мы увеличиваем процент объяснённой дисперсии всего на 5%, что позволяет нам не учитывать эту информацию.\n",
    "\n",
    "![pca2](pictures/pca2.png)\n",
    "\n",
    "Таким образом, корреляционная прямая, новая ось РС1, становится одной новой переменной (интегративной переменной) вместо двух переменных по осям OX и OY. Это позволяет нам снизить размерность данных.\n",
    "\n",
    "![biplot](pictures/biplot.png)\n",
    "\n",
    "Если на графике biplot угол между переменными равен 90 градусов, значит коэффициент корреляции межу ними равняется нулю.\n",
    "\n",
    "[Пример анализа главных компонент, когда переменных больше двух](https://stepik.org/lesson/27111/step/6?unit=8681)\n",
    "\n",
    "<br/><br/>\n",
    "<center><span style=\"color: violet; font-weight: bold; font-size:14pt\">Факторный анализ</span></center>\n",
    "\n",
    "![factor](pictures/factor.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
